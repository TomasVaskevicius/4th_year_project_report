\documentclass[report.tex]{subfiles}

\begin{document}

\chapter{Introduction}

\section{A Brief History of the Monte Carlo Method}
\label{chapter1-introduction}

In 1946 a Polish-American mathematician Stanisław Ulam\footnote{
  Stan, currently one of the most widely used probabilistic programming languages
  providing full Bayesian inference, is named after Stanisław Ulam
  \cite{stanReferenceManual}.
}
was playing Canfield solitaire while recovering from brain surgery.
He got interested in computinig the probability of winning based on the initial
layout of cards. After unsucessfully spending a lot of time trying to calculate it
by pure combinatorial approaches it occured to him that simply playing the
game, say one hundred times and obtaining a rough estimate might be of more
practical use \cite{eckhardt1987stan}. Using repeated random sampling
to obtain numerical approximations for intractable problems is at the
core of the Monte Carlo method.

The idea of statistical sampling itself was not new at the time. For example,
the Italian physicist Enrico Fermi used it to study neutron diffusion in the
early 1930s. Such techniques had fallen out of use because of the
length and tediousness of the calculations, which at the time had to be
performed by humans. However, in February 1946 one of the earliest electronic
general-purpose computer ENIAC was announced to the public. The key insight of
Stanisław Ulam was that ENIAC's computing power could be used to revive these
statistical sampling techniques \cite{metropolis1987beginning}, whose significance
was soon recognised by John von Neumann. Thus began the rapid development of
Monte Carlo techniques.

The first unclassified paper on the Monte Carlo method appeared in 1949, written
by \citet{metropolis1949monte}. Four years later, the first Markov chain Monte Carlo
(MCMC) approach was developed in Los Alamos by physicists \citet{metropolis1953equation}.
In 1970 it was generalized by \citet{hastings1970monte} to what is now
known as the Metropolis-Hastings algorithm. Despite extensive
use of MCMC algorithms by physicists, it only made an impact on the statistical
community in the early 1990s, marked by the seminal paper of
\citet{gelfand1990sampling}. Since then MCMC has been a very active area of
research in Statistics. Indeed, almost half of the articles found by a
Google Scholar search using the keyword "MCMC" were published after the year 2000.

In 2012 a fundamentally different MCMC algorithm by \citet{peters2012rejection}
appeared in the physics literature. This new algorithm relies on simulation of
a continuous-time non-reversible piecewise-deterministic Markov (PDMP) process. In
contrast, many other MCMC techniques are variations of the
Metropolis-Hastings algorithm and hence rely on simulation of a discrete-time
reversible Markov chain.
The new algorithm by \citet{peters2012rejection}
was generalised by \citet{bouchard2015bouncy},
where theoretical guarantees and extensive analysis is given.
It has been also shown to compare favourably with the current
state-of-the-art methods on various Bayesian inference tasks and to be
particularly suitable for the big data setting.
Similarly promising results were obtained by an even more recent PDMP based
MCMC algorithm by \citet{bierkens2016zig}.

\section{Project Goals}
\label{project-goals-section}

Apart from very encouraging performance results, the Bouncy Particle Sampler (BPS)
\cite{peters2012rejection, bouchard2015bouncy}
and the Zig-Zag process \cite{bierkens2016zig}
possess one very desirable quality that is not present in most of the other algorithms --
non-reversibility of the simulated Markov process.
See, for example, \citet{neal2004improving} or \citet{sun2010improving} for the role
that non-reversibility plays in MCMC algorithms.
PDMP based Monte Carlo algorithms are thus rapidly becoming a very active and promising
research direction.

Implementing such algorithms is, however, not the easiest task.
The main difficulty comes from the simulation of
PDMPs; however, the technique for simulating PDMPs across different MCMC algorithms
could be reused.
It is thus very inefficient to develop such algorithms from
scratch, which unfortunately seems to currently be the case.
Writing a generalised and
reusable software is difficult and time consuming.
Most researchers thus understandably opt to implement their novel algorithms in
the quickest and the most direct way possible, which results in code that is
hard to reuse.

In this project, we aim to contribute to future research of developing
novel PDMP based Monte Carlo algorithms by developing a framework for efficient
simulation and analysis of as general PDMPs as possible.
This framework will allow to focus on the structure of the underlying PDMPs rather
than on tedious implementation details.
We expect our software to be \textit{efficient}, \textit{flexible},
\textit{reliable}, \textit{relevant} and \textit{easy to use}.

\section{Project Outline}

\begin{itemize}
  \item In \textit{Chapter 2} we provide the background material on PDMPs and
    their simulation.
  \item In \textit{Chapter 3} we design and implement a framework for efficiently
    simulating arbitrary PDMPs.
  \item In \textit{Chapter 4} we design an output analysis framework.
  \item In \textit{Chapter 5} we show how our framework can be used to implement
    the Bouncy Particle Sampler and the Zig-Zag process.
  \item In \textit{Chapter 6} we summarise what we managed to achieve in this project
    and reflect on the development process.
\end{itemize}

\end{document}

